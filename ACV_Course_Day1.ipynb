{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "99knUsbUjGcj"
   },
   "source": [
    "# ACV Course\n",
    "\n",
    "## Overview :\n",
    "Main goal of the course: learn how to manipulate and analyse images OpenCV, focused on skills needed for computer vision outside of machine learning methods.\n",
    "\n",
    "We start by 2 days on image processing and manipulation :\n",
    "- Day 1 : Basics of image processing in OpenCV\n",
    "- Day 2 : Advanced image manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imBDnfexltBM"
   },
   "source": [
    "## Program for today\n",
    "\n",
    "### Morning: Interactive course\n",
    "* Image input/output\n",
    "* Manipulating pixels\n",
    "* Color spaces\n",
    "* Blurring images\n",
    "* Edge detection\n",
    "* Morphological operations\n",
    "* Thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NAU903b7pBSd"
   },
   "source": [
    "### Afternoon: Start of the project\n",
    "**General goal**\n",
    "\n",
    "Build a webcam filter app like PhotoBooth on Mac OS (demo)\n",
    "\n",
    "**Today's goals**\n",
    "\n",
    "Develop some filters:\n",
    "* Mirror\n",
    "* Glow\n",
    "* Sepia\n",
    "* Black and white\n",
    "* X-Ray\n",
    "* Cartoon\n",
    "* Bonus: Drawing\n",
    "* Bonus: Thermal camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbHDC3SFiedW",
    "nbpresent": {
     "id": "a1921d95-f5ce-41d6-b399-9a7c5af9cb3c"
    }
   },
   "source": [
    "## Why OpenCV\n",
    "\n",
    "* OpenCV = Open Computer Vision Library\n",
    "* Vision, image & video processing, and machine learning libraries rolled into one\n",
    "* Multiplatform and multilanguage\n",
    "* Free and open source\n",
    "* Used by basically everyone working on Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhOmEscZiedW",
    "nbpresent": {
     "id": "d3975a40-18ac-4026-8a39-b4157cc21d53"
    }
   },
   "source": [
    "**Applications**\n",
    "\n",
    "* Tracking and identifying objects (including humans)\n",
    "* Tracking camera motion\n",
    "* 3D model reconstruction\n",
    "* Search by image\n",
    "* And much more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kdhbYts5iedX",
    "nbpresent": {
     "id": "213eb2b0-b658-46ce-a72f-215a82c5cc7c"
    }
   },
   "source": [
    "**Examples of industrial use cases**\n",
    "* Stitching streetview images together\n",
    "* Monitoring mine equipment in China \n",
    "* Helping robots navigate and pick up objects at Willow Garage\n",
    "* Detection of swimming pool drowning accidents in Europe\n",
    "* Running interactive art in Spain and New York\n",
    "* Checking runways for debris in Turkey\n",
    "* Inspecting labels on products in factories around the world\n",
    "* Rapid face detection in Japan\n",
    "\n",
    "http://opencv.org/about.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "shSC-S0tqmZm"
   },
   "source": [
    "### Useful ressources\n",
    "\n",
    "Tutorials:\n",
    "http://docs.opencv.org/3.1.0/d6/d00/tutorial_py_root.html\n",
    "\n",
    "Reference:\n",
    "http://docs.opencv.org/2.4/index.html\n",
    "\n",
    "\n",
    "Community:\n",
    "http://stackoverflow.com/questions/tagged/opencv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JNSk6GfTwmDq"
   },
   "source": [
    "## Preparation\n",
    "\n",
    "We will use Colab and we will need to download and unzip some files that we will use along the course.\n",
    "\n",
    "Colab does not keep the files between sessions, so you will probably need to redownload it each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "djLFWrAGxHQq"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!unzip -o data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_48su4Siedc",
    "nbpresent": {
     "id": "7fb97c5e-4092-4e4e-8023-b795f49791da"
    }
   },
   "source": [
    "Essential utility commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hPpIwKaaiedc",
    "nbpresent": {
     "id": "e0937ba9-ac52-4500-9355-f809320da00f"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [15, 10]  # Make inline plots larger\n",
    "\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_vTGcIMryjx2"
   },
   "source": [
    "Because we are using Colab, we will need a patch to diplay images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "DWuAZ8YdyiW8"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16802/2166553481.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatches\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "cv2.imshow = lambda title,im: cv2_imshow(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1yIlE5Hiedd",
    "nbpresent": {
     "id": "912cb702-4e13-45e3-be96-8ca5bb075111"
    }
   },
   "source": [
    "## Image input/output \n",
    "### Reading and displaying image with numpy/matplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "id": "5BFV2l5niedd",
    "nbpresent": {
     "id": "b6b7891d-3c45-408b-b1e0-9ff049e33104"
    },
    "outputId": "9680f3c1-e2c5-49ee-d106-c8ccb7bba534"
   },
   "outputs": [],
   "source": [
    "im2disp = plt.imread('data/home.jpg')\n",
    "plt.figure()\n",
    "plt.imshow(im2disp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B65XKuYqiede",
    "nbpresent": {
     "id": "fcdb542e-a920-41f2-9b8b-a6fe3b47f4a4"
    }
   },
   "source": [
    "### Now the OpenCV way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "id": "tXZpzVftiede",
    "nbpresent": {
     "id": "ae7b3af1-e0c2-4011-8fb6-ae6794c5dfa9"
    },
    "outputId": "39c6ea91-7b9a-43ee-acec-cbe8fc6afd7e"
   },
   "outputs": [],
   "source": [
    "cvim2disp = cv2.imread('data/home.jpg')\n",
    "cv2.imshow('HelloWorld', cvim2disp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJ6dd7Ssiedf",
    "nbpresent": {
     "id": "0a2e56df-667e-41b7-a35f-fb58ddaf997b"
    }
   },
   "source": [
    "### Are numpy.imshow and cv2.imshow the same?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "id": "chSogn5iiedf",
    "nbpresent": {
     "id": "aa164811-7136-40e4-8093-31a0a67b944f"
    },
    "outputId": "82a6a9cc-ce70-48bd-8c80-ab94902337b2"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(cvim2disp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "daJptg6Aiedf",
    "nbpresent": {
     "id": "45a597e1-1a3d-4e04-b570-92fb942bbbc8"
    }
   },
   "source": [
    "**What happened??**\n",
    "\n",
    "For historical reasons, OpenCV defaults to BGR format instead of usual RGB\n",
    "\n",
    "**Solutions:**\n",
    "\n",
    "Use numpy/OpenCV consistently\n",
    "\n",
    "or make sure to convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "id": "R1Inorpciedg",
    "nbpresent": {
     "id": "dfa4b5ff-7f56-4a23-84b4-af0ac0e890ca"
    },
    "outputId": "ac38ab00-a78d-4ad6-8b8a-9d065100c8ec"
   },
   "outputs": [],
   "source": [
    "cvimrgb = cv2.cvtColor(cvim2disp,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#or\n",
    "#imbgr = cv2.cvtColor(im2disp,cv2.COLOR_RGB2BGR)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(cvimrgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RpeDRRvE2IsW"
   },
   "source": [
    "### Other color spaces (HSL, HSV, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "id": "NkTo4ngC2VKb",
    "outputId": "b8e81104-8640-4524-b4ef-5b32e4e88455"
   },
   "outputs": [],
   "source": [
    "cvimhsv = cv2.cvtColor(cvim2disp,cv2.COLOR_BGR2HSV)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(cvimhsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jkKJsHCu3ghz"
   },
   "source": [
    "**Why does it look like this?**\n",
    "\n",
    "HSV = Hue, Saturation, Value\n",
    "\n",
    "https://en.wikipedia.org/wiki/HSL_and_HSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "LR4D55Vi4bFs",
    "outputId": "6f2ff9ce-956e-4560-91e2-711c073b5105"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title('Hue')\n",
    "plt.imshow(cvimhsv[:, :, 0], cmap='gray')\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Saturation')\n",
    "plt.imshow(cvimhsv[:, :, 1], cmap='gray')\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Value (~= Luminosity)')\n",
    "plt.imshow(cvimhsv[:, :, 2], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uupvWQMviedh"
   },
   "source": [
    "### Simple filtering example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "id": "mGR1ZMnciedh",
    "outputId": "c26c4f55-3d54-428a-adb1-0fc99ff3ff58"
   },
   "outputs": [],
   "source": [
    "im2disp = plt.imread('data/home.jpg')\n",
    "\n",
    "blurred = cv2.GaussianBlur(im2disp,(19,19),0)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(blurred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9bVsT0XPzc2c"
   },
   "source": [
    "A more general method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "id": "Lx87vDQWzYoU",
    "outputId": "5cc94430-ec45-4fbf-c69a-fe1bde23ac56"
   },
   "outputs": [],
   "source": [
    "kernel = np.ones((5,5),np.float32)/25\n",
    "blurred2 = cv2.filter2D(im2disp,-1,kernel)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(blurred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WP1p4klHiedh",
    "nbpresent": {
     "id": "0b2b252f-dc8d-46b3-865c-d91e5a67ed6a"
    }
   },
   "source": [
    "### Saving an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J2tpyQnliedh",
    "nbpresent": {
     "id": "b580a43e-03cd-4fdc-8f0d-e69653969251"
    }
   },
   "outputs": [],
   "source": [
    "cv2.imwrite('mycvimage.png', cvim2disp)\n",
    "#or\n",
    "plt.imsave('myimage.png', im2disp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ELx8lrWiedh",
    "nbpresent": {
     "id": "1501269c-2107-40a8-a8ab-d46443c5c133"
    }
   },
   "source": [
    "### Bonus: 1 numpy gotcha for people coming from Matlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GYarZXEciedi",
    "nbpresent": {
     "id": "1aee9993-9a16-4053-bfc8-e97ea1fabbdb"
    },
    "outputId": "ee41bd70-702d-43eb-e299-d85cd3be781a"
   },
   "outputs": [],
   "source": [
    "x = zeros(5)\n",
    "y = x\n",
    "\n",
    "y[1] = 1\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IaRV0VCGiedi",
    "nbpresent": {
     "id": "0f618461-e7ba-41e3-9416-e70fd18e03d5"
    }
   },
   "source": [
    "**What happened? Why did modifying y change x?**\n",
    "\n",
    "A: Python copies arrays and other mutable data types by reference by default\n",
    "\n",
    "Here's what you probably want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GP2ZmwYHiedi",
    "nbpresent": {
     "id": "285b7d68-b953-4b9e-8095-9e28a454adee"
    },
    "outputId": "13d75b22-3751-4dda-fb74-4d9302f8607d"
   },
   "outputs": [],
   "source": [
    "x = zeros(5)\n",
    "y = x.copy()\n",
    "\n",
    "y[1] = 1\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F096nAepilBS"
   },
   "source": [
    "##Essential Numpy for OpenCV image work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kFPvDDLD5gMD"
   },
   "source": [
    "Let's load a nice picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "id": "ak7WYGJuilBW",
    "outputId": "357cd8b4-d98b-452b-d669-c55a188c284f"
   },
   "outputs": [],
   "source": [
    "bfly = plt.imread('data/butterfly.jpg')\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(bfly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NmELboI15wGz"
   },
   "source": [
    "Many algorithms operate on grayscale, and grayscale is easier to work on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "id": "uFY_T9S1ilBW",
    "outputId": "f7a80743-271c-4e00-e7e5-e050f69e8085"
   },
   "outputs": [],
   "source": [
    "bflygray = cv2.cvtColor(bfly,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(bflygray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UxfQYB1J55i8"
   },
   "source": [
    "You may or may not want the default rainbow map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "id": "un613MaXilBX",
    "outputId": "5d4345a8-8d39-4dbb-9ce3-55796a76f424"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(bflygray, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q41SsnL95_uy"
   },
   "source": [
    "Let's make sure we understand our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ykzAzFJwilBY",
    "outputId": "f9802f3d-dc2d-429e-c6d1-827090e271ef"
   },
   "outputs": [],
   "source": [
    "print(bfly.shape)\n",
    "print(bflygray.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kyzT2iCXilBZ"
   },
   "source": [
    "The format above is (height, width, numchannels):\n",
    "\n",
    "* If numchannels = 1, as is for grayscale, it is omitted\n",
    "\n",
    "* For RGB/BGR/HSV color images, numchannels=3\n",
    "\n",
    "* You could have numchannels=4; this happens for RGBA (Red, Green, Blue, Alpha) images, where Alpha is transparency\n",
    "  * transparent = 0\n",
    "  * opaque = 1.0 or 255 (depending on your datatype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-nP6toVz7Fc0"
   },
   "source": [
    "Also remember how to get the data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rT7NIjhCilBZ",
    "outputId": "2db261b5-2199-40a9-aaa6-48e1c555950d"
   },
   "outputs": [],
   "source": [
    "bfly.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ee4T2aTU7LO2"
   },
   "source": [
    "uint8, which means integers in the 0-255 range, is standard for everyday camera images\n",
    "\n",
    "For scientific purposes, floating point is often used. We typically want these in the 0-1 range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pb-ozHzfilBZ",
    "outputId": "5abe7122-3588-4ad1-b9b1-14b1f7e426da"
   },
   "outputs": [],
   "source": [
    "bflyfloat = bflygray.astype(double) / 255.0\n",
    "\n",
    "bflyfloat.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w0GfBchj7i8j"
   },
   "source": [
    "Going back to dimensions, how do we get the image width and height in convenient variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UuFItKr9ilBa"
   },
   "outputs": [],
   "source": [
    "height, width = bflygray.shape[0:2]\n",
    "\n",
    "height, width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YC_WdQl07wEp"
   },
   "source": [
    "**Always remember that the y dimension comes first**\n",
    "\n",
    "=> height is before width\n",
    "\n",
    "**When indexing, [0:2] is only 0 and 1, not 0,1,2**\n",
    "\n",
    "Python uses a 0:N-1 convention, which is handy when you get used to it, but can trip up newcomers\n",
    "\n",
    "**What would you expect the following to do?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iWIKdx9UilBa",
    "outputId": "16eac755-3c5b-4fdc-da16-a7862174d350"
   },
   "outputs": [],
   "source": [
    "print(np.arange(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y4RHCF9X8Q7x"
   },
   "source": [
    "Also, you might see something like this in people's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p70ue4D5ilBb"
   },
   "outputs": [],
   "source": [
    "height, width = bflygray.shape[:2]\n",
    "\n",
    "height, width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HqRG6kdT8XW7"
   },
   "source": [
    "It works just the same; when you leave an index blank, it's assumed to be the first or last element, depending on whether it's on the left or right of the : char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nl5JXILVilBc",
    "outputId": "827d1114-f71c-4d11-9bd9-36e91d6b38e9"
   },
   "outputs": [],
   "source": [
    "bfly.shape[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K4d3u4jg8ftE"
   },
   "source": [
    "Also useful to know how to access the last, second to last etc elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AZh08dNnilBc",
    "outputId": "60cbf371-2b32-483e-9990-cf5fb5ac00f0"
   },
   "outputs": [],
   "source": [
    "print(bfly.shape[-1])\n",
    "print(bfly.shape[-2])\n",
    "print(bfly.shape[-3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gNfvBfjw8lRk"
   },
   "source": [
    "You can probably guess how to extract RGB channels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P5pnWUZrilBc"
   },
   "outputs": [],
   "source": [
    "redc = bfly[:,:,0]\n",
    "greenc = bfly[:,:,1]\n",
    "bluec = bfly[:,:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cc-9-_6c8p46"
   },
   "source": [
    "Note that these will all be singleton in the numchannels dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I80G4DJnilBc",
    "outputId": "61e2b364-41ce-420b-b6d1-ec095a61e3e9"
   },
   "outputs": [],
   "source": [
    "bluec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LinWJvf38wWJ"
   },
   "source": [
    "**How to recombine?**\n",
    "\n",
    "First create a new blank image of the proper dimensions\n",
    "\n",
    "Be careful that the dimensions are given as a tuple rather than individual arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "id": "sD8HeQEMilBd",
    "outputId": "826d1b3f-9588-4532-ba4c-88b72832edaa"
   },
   "outputs": [],
   "source": [
    "combined = np.zeros((height,width,3), uint8)\n",
    "\n",
    "combined[:,:,0] = redc\n",
    "combined[:,:,1] = greenc\n",
    "combined[:,:,2] = bluec\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nBgPSuWI9GLQ"
   },
   "source": [
    "It's easy to extract a region of interest from an image\n",
    "\n",
    "Let's say we want to examine the butterfly's head more closely;\n",
    "\n",
    "We can get a bounding box from the figure above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "id": "F_wUTOZBilBd",
    "outputId": "01fce034-5aa0-49f9-e6eb-7c09ff705b1f"
   },
   "outputs": [],
   "source": [
    "bflyhead = bfly[70:100,210:250]\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(bflyhead)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvoSWaXP9SAC"
   },
   "source": [
    "Writing to pixels is also simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "id": "eEmhb7gCilBd",
    "outputId": "59ff999c-1bf7-4f64-9300-1919364befdb"
   },
   "outputs": [],
   "source": [
    "bflyedit = bfly.copy()\n",
    "bflyedit[70:100,210:250] = 0\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(bflyedit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "phzZ67fwilBd"
   },
   "source": [
    "Suggested test-your-knowledge exercises:\n",
    "1.  Take an image and write a big + sign over it (ie two blocks of black pixels; one extending from top to bottom, one from left to right, but not occupying the whole image)\n",
    "2.  Create a function that will take in two images and return an image that combines them into a larger side-by-side image\n",
    "Should be something like\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xUYlqca7ilBe"
   },
   "outputs": [],
   "source": [
    "def sidebyside(imageleft,imageright):\n",
    "    newimheight = ...\n",
    "    newimwidth = ...\n",
    "    newim = plt.zeros(...)\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    return newim\n",
    "\n",
    "#note this won't run as-is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BT6SAGT8-ZtV"
   },
   "source": [
    "### Numpy addition vs OpenCV addition\n",
    "\n",
    "Numpy does modular addition (ie 250+10 = 4, assuming uint8)\n",
    "\n",
    "OpenCV saturates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X_Qs16pailBe",
    "outputId": "48f22d57-4d8e-48e3-b5fc-7b2b8d1acfd6"
   },
   "outputs": [],
   "source": [
    "x = np.uint8([250])\n",
    "y = np.uint8([10])\n",
    "\n",
    "cv2.add(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QpJ3YODL-r1t"
   },
   "source": [
    "This tends to be what you want for combining images\n",
    "\n",
    "cv2.subtract works similarly\n",
    "\n",
    "Of course, images will have to be the same dimension for addition/subtraction to work\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hqduGv-0-0x8"
   },
   "source": [
    "### Image weighted blending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MZhlZnUq_AMg"
   },
   "source": [
    "Make sure alpha values (or image weights) sum to 1, if you want to \"conserve brightness\"\n",
    "\n",
    "alpha for pic1 = 0.7\n",
    "\n",
    "alpha for pic2 = 1 - 0.7 = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "id": "9MPEumi7-8i6",
    "outputId": "4f114573-7a7c-4f4d-bd45-8c9ea313d5a6"
   },
   "outputs": [],
   "source": [
    "pic1 = plt.imread('data/pic1.png')\n",
    "pic2 = plt.imread('data/pic2.png')\n",
    "\n",
    "dst = cv2.addWeighted(pic1, 0.7, pic2, 0.3, 0)\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(pic1)\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(pic2)\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0qJIQPbgilBe"
   },
   "source": [
    "## Image filtering in OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z0zBTHHuilBf"
   },
   "source": [
    "### Lowpass filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "id": "jDBwx6vGilBf",
    "outputId": "b0d00772-80bc-41d2-e658-18e01d88882e"
   },
   "outputs": [],
   "source": [
    "baboon = imread('data/baboon.jpg')\n",
    "babblur = cv2.GaussianBlur(baboon, (29,29), 0)\n",
    "\n",
    "#custom kernel; simple box-car in this case\n",
    "kernel = np.ones((15,15), np.float32)\n",
    "kernel /= kernel.size #normalize kernel so as not to scale image intensity\n",
    "\n",
    "babblur2 = cv2.filter2D(baboon, -1, kernel)\n",
    "\n",
    "figure()\n",
    "subplot(1,3,1)\n",
    "imshow(baboon)\n",
    "title('original')\n",
    "subplot(1,3,2)\n",
    "imshow(babblur)\n",
    "title('Gaussian blurred')\n",
    "subplot(1,3,3)\n",
    "imshow(babblur2)\n",
    "title('Box-car blurred')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RXtulbgjAvnA"
   },
   "source": [
    "Filter2D is very general and can do many different things; with the right kernel\n",
    "\n",
    "You can just as easily do high-pass filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N2DiLLw_A2y6"
   },
   "source": [
    "### Median blurring\n",
    "\n",
    "Smoothing filter while preserving edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 600
    },
    "id": "at8pf5U0ilBf",
    "outputId": "5614704a-e50e-41a7-804e-9bb119c64541"
   },
   "outputs": [],
   "source": [
    "t = linspace(-1.0,1,1000)\n",
    "y =  200* (exp(-(t/0.3)**20)  )\n",
    "yn = y + 200*random.normal(scale=0.01,size=t.shape)\n",
    "yn[yn<0]=0\n",
    "y = y.astype(uint8)\n",
    "yn = yn.astype(uint8)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(t, y)\n",
    " \n",
    "plt.plot(t, yn)\n",
    " \n",
    "ygb = cv2.GaussianBlur(y,(199,199),0)\n",
    "plt.plot(t, ygb)\n",
    " \n",
    "ymb = cv2.medianBlur(y,199)\n",
    "plt.plot(t, ymb)\n",
    " \n",
    "plt.legend(['original', 'w/ noise', 'Gaussian blur', 'Median blur'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fZ43OpXFBNLb"
   },
   "source": [
    "Fun demonstration of median-blur to \"cartoonify\" a real image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "id": "I2PNsK3SilBf",
    "outputId": "032a1512-05d5-45e7-d3aa-769a64720a24"
   },
   "outputs": [],
   "source": [
    "tulips = imread('data/tulips.jpg')\n",
    "tublur = cv2.medianBlur(tulips, 29)\n",
    "\n",
    "# We'll cover Canny edge detection and dilation shortly\n",
    "edge = cv2.Canny(tublur, 10, 150)\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "edge = cv2.dilate(edge, kernel, iterations = 1)\n",
    "tublur[edge==255] = 0\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(tulips)\n",
    "plt.title('original')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(tublur)\n",
    "plt.title('cartoonified')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WlK3qVNfilBg"
   },
   "source": [
    "### Highpass filtering and edge-detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fXr0Fl9CilBg"
   },
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/20/%C3%84%C3%A4retuvastuse_n%C3%A4ide.png/500px-%C3%84%C3%A4retuvastuse_n%C3%A4ide.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAbsP9B_Bxjk"
   },
   "source": [
    "Basic high-pass filtering example\n",
    "\n",
    "High-pass filtering responds to derivatives, or spatial changes in images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 594
    },
    "id": "i-0_L4AJilBg",
    "outputId": "e4e3f5ab-b73b-4fcf-fade-d34054012a11"
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('data/sudokubig.jpg', cv2.IMREAD_GRAYSCALE)\n",
    " \n",
    "laplacian = cv2.Laplacian(img, cv2.CV_64F)\n",
    "sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=5)\n",
    "sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=5)\n",
    " \n",
    "plt.figure()\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title('Original'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(laplacian, cmap='gray')\n",
    "plt.title('Laplacian')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.clim([0, 45])\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(sobelx, cmap='gray')\n",
    "plt.title('Sobel X')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.clim([0, 4500])\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow(sobely, cmap='gray')\n",
    "plt.title('Sobel Y')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.clim([0, 4500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOPALQrHEP0R"
   },
   "source": [
    "### Canny edge detection\n",
    "\n",
    "Read about the theory here:\n",
    "\n",
    "https://docs.opencv.org/4.0.0/da/d22/tutorial_py_canny.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "id": "IpQLiA7YilBg",
    "outputId": "e6c8524c-7c3f-46a5-a69e-05897bce1904"
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('data/messi.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "edge = cv2.Canny(img, 100, 200)\n",
    " \n",
    "plt.figure()\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.title('Original Image')\n",
    "plt.imshow(img, cmap='gray')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('Edge Image')\n",
    "plt.imshow(edge, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "chlnkcdwilBg"
   },
   "source": [
    "### Morphological Operations\n",
    "\n",
    "Modifying binary masks\n",
    "\n",
    "Read about the different operations here:\n",
    "\n",
    "https://docs.opencv.org/4.0.0/d9/d61/tutorial_py_morphological_ops.html#gsc.tab=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "id": "KJJUXnMsilBh",
    "outputId": "14ca0cdc-106e-4e33-9b18-1f4c7bf9e437",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a doughnut/circle image/mask of 0's and 1's\n",
    "yy=mgrid[-1:1:0.01,-1:1:0.01][0]\n",
    "xx=yy.T\n",
    "circ = 0*xx\n",
    "circ [xx**2+yy**2 < 0.5**2 ]=1\n",
    "circ [xx**2+yy**2 < 0.2**2 ]=0\n",
    " \n",
    "# Many different kernel types depending on application\n",
    "# Let's just stick with a simple box kernel\n",
    "kernel = ones((10,10), float32)\n",
    "\n",
    "# Now let's try the some of the different morphological operations\n",
    "erosion = cv2.erode(circ, kernel, iterations=1)\n",
    "\n",
    "dilation = cv2.dilate(circ, kernel, iterations=1)\n",
    "\n",
    "floodfilled = cv2.floodFill(image=circ.astype(uint8).copy(), mask=None, seedPoint=(100,100), newVal=1)\n",
    " \n",
    "plt.figure()\n",
    "\n",
    "plt.subplot(1,4,1)\n",
    "plt.title('doughnut')\n",
    "plt.imshow(circ, cmap='gray')\n",
    "\n",
    "plt.subplot(1,4,2)\n",
    "plt.title('eroded')\n",
    "plt.imshow(erosion, cmap='gray')\n",
    "\n",
    "plt.subplot(1,4,3)\n",
    "plt.title('dilated')\n",
    "plt.imshow(dilation, cmap='gray')\n",
    "\n",
    "plt.subplot(1,4,4)\n",
    "plt.title('flood-filled')\n",
    "plt.imshow(floodfilled[1].astype(float32), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qIvZzX3milBh"
   },
   "source": [
    "### Adaptive Thresholding\n",
    "\n",
    "Compare hard thresholding to adaptive thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 594
    },
    "id": "oHjdsiBeilBi",
    "outputId": "06f92249-82b0-438a-db51-46eca8e9749c"
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('data/sudokubig.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "img = cv2.medianBlur(img, 5)\n",
    "\n",
    "ret, th1 = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
    "th2 = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "th3 = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    " \n",
    "titles = ['Original Image', 'Global Thresholding (v = 127)',\n",
    "            'Adaptive Mean Thresholding', 'Adaptive Gaussian Thresholding']\n",
    "images = [img, th1, th2, th3]\n",
    "\n",
    "plt.figure()\n",
    "for i, (title, image) in enumerate(zip(titles, images)):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(title)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "ACV_Course_Day1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "nbpresent": {
   "slides": {
    "019925b6-3427-4056-b7b3-037d5ada7af0": {
     "id": "019925b6-3427-4056-b7b3-037d5ada7af0",
     "prev": "884850c7-78aa-4ef5-85aa-78e84e04fcbb",
     "regions": {
      "8e599505-bab1-4ed7-98ae-aa13673ffe1e": {
       "attrs": {
        "height": 0.28205128205128205,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "912cb702-4e13-45e3-be96-8ca5bb075111",
        "part": "whole"
       },
       "id": "8e599505-bab1-4ed7-98ae-aa13673ffe1e"
      },
      "dc527f95-5ef0-44ac-921f-083f4073e6ab": {
       "attrs": {
        "height": 0.2,
        "width": 0.4,
        "x": 0.5,
        "y": 0.7
       },
       "id": "dc527f95-5ef0-44ac-921f-083f4073e6ab"
      },
      "df98168a-6f2a-425e-8fa4-e23c90fc85fe": {
       "attrs": {
        "height": 0.5008547008547009,
        "width": 0.823076923076923,
        "x": 0.10096153846153846,
        "y": 0.43333333333333335
       },
       "content": {
        "cell": "b6b7891d-3c45-408b-b1e0-9ff049e33104",
        "part": "whole"
       },
       "id": "df98168a-6f2a-425e-8fa4-e23c90fc85fe"
      }
     }
    },
    "0b3bb0d8-7b62-45e2-bdea-56d1ddb07065": {
     "id": "0b3bb0d8-7b62-45e2-bdea-56d1ddb07065",
     "prev": "9fd2fc08-8f31-40b1-9c43-bc006b638a09",
     "regions": {
      "8ffac7cb-51dc-4754-9338-e40e26852937": {
       "attrs": {
        "height": 1,
        "width": 1,
        "x": 0,
        "y": 0
       },
       "content": {
        "cell": "89b2c70c-1b84-4f3f-bf48-713d641d25ce",
        "part": "whole"
       },
       "id": "8ffac7cb-51dc-4754-9338-e40e26852937"
      }
     }
    },
    "3a0e5011-0f74-4bc4-b4dd-84d1602d1e4d": {
     "id": "3a0e5011-0f74-4bc4-b4dd-84d1602d1e4d",
     "prev": "7514c99a-224c-4a85-a967-5195636ae76e",
     "regions": {
      "d37cf75d-0732-4701-8ab1-9cd15bc8e80b": {
       "attrs": {
        "height": 1,
        "width": 1,
        "x": 0,
        "y": 0
       },
       "content": {
        "cell": "7426b6e0-8b90-4847-86b7-9507511d807f",
        "part": "whole"
       },
       "id": "d37cf75d-0732-4701-8ab1-9cd15bc8e80b"
      }
     }
    },
    "6833f6d3-659c-4600-9c08-d89984d9ef0d": {
     "id": "6833f6d3-659c-4600-9c08-d89984d9ef0d",
     "prev": "c640b2e3-23c3-406e-a06e-88bc91506535",
     "regions": {
      "35872901-5898-436f-b3fc-fa00fffe05a9": {
       "attrs": {
        "height": 1,
        "width": 1,
        "x": 0,
        "y": 0
       },
       "content": {
        "cell": "ed398bf3-86cf-4a55-ae1d-c8c9b557ef97",
        "part": "whole"
       },
       "id": "35872901-5898-436f-b3fc-fa00fffe05a9"
      }
     }
    },
    "7514c99a-224c-4a85-a967-5195636ae76e": {
     "id": "7514c99a-224c-4a85-a967-5195636ae76e",
     "prev": "0b3bb0d8-7b62-45e2-bdea-56d1ddb07065",
     "regions": {
      "0a2bd284-d113-4f41-ad11-098bd03ac74f": {
       "attrs": {
        "height": 1,
        "width": 1,
        "x": 0,
        "y": 0
       },
       "content": {
        "cell": "1460f643-a4f5-40e8-b2df-588ccf04bbc6",
        "part": "whole"
       },
       "id": "0a2bd284-d113-4f41-ad11-098bd03ac74f"
      }
     }
    },
    "7d81e3c9-81e7-4c29-8022-538a15107a84": {
     "id": "7d81e3c9-81e7-4c29-8022-538a15107a84",
     "prev": "7fabf334-8dfb-4e29-ae1e-f8f321a75e33",
     "regions": {
      "51efe400-52e5-4e34-8685-83fd3618ff49": {
       "attrs": {
        "height": 1,
        "width": 1,
        "x": 0,
        "y": 0
       },
       "content": {
        "cell": "d3975a40-18ac-4026-8a39-b4157cc21d53",
        "part": "whole"
       },
       "id": "51efe400-52e5-4e34-8685-83fd3618ff49"
      }
     }
    },
    "7df09def-93b5-4d91-b080-6e2fae564ee0": {
     "id": "7df09def-93b5-4d91-b080-6e2fae564ee0",
     "prev": "9d0acc82-b4d0-4258-bfcb-54751095872c",
     "regions": {
      "7dc8ff01-1d4b-45a1-a278-7487ce352e48": {
       "attrs": {
        "height": 0.1675213675213675,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "id": "7dc8ff01-1d4b-45a1-a278-7487ce352e48"
      },
      "d9d4dc18-ef7c-4938-8466-6760ebd8ff61": {
       "attrs": {
        "height": 0.2,
        "width": 0.4,
        "x": 0.5,
        "y": 0.7
       },
       "id": "d9d4dc18-ef7c-4938-8466-6760ebd8ff61"
      },
      "ec757ce9-6955-48e4-8dbb-69c023496362": {
       "attrs": {
        "height": 0.5743589743589743,
        "width": 0.8413461538461539,
        "x": 0.1,
        "y": 0.32564102564102565
       },
       "id": "ec757ce9-6955-48e4-8dbb-69c023496362"
      }
     }
    },
    "7fabf334-8dfb-4e29-ae1e-f8f321a75e33": {
     "id": "7fabf334-8dfb-4e29-ae1e-f8f321a75e33",
     "prev": "ca856989-0a9b-4281-83e3-ded0c06af816",
     "regions": {
      "4a6b784d-7fb4-4034-b9c9-e8e3d49ccbdb": {
       "attrs": {
        "height": 1,
        "width": 1,
        "x": 0,
        "y": 0
       },
       "content": {
        "cell": "a1921d95-f5ce-41d6-b399-9a7c5af9cb3c",
        "part": "whole"
       },
       "id": "4a6b784d-7fb4-4034-b9c9-e8e3d49ccbdb"
      }
     }
    },
    "884850c7-78aa-4ef5-85aa-78e84e04fcbb": {
     "id": "884850c7-78aa-4ef5-85aa-78e84e04fcbb",
     "prev": "6833f6d3-659c-4600-9c08-d89984d9ef0d",
     "regions": {
      "288c0e6a-f3ae-4f67-93b6-8a55e9634db1": {
       "attrs": {
        "height": 0.21025641025641026,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "7fb97c5e-4092-4e4e-8023-b795f49791da",
        "part": "whole"
       },
       "id": "288c0e6a-f3ae-4f67-93b6-8a55e9634db1"
      },
      "4235e07a-e2e1-494e-aa2e-44cb3bc0908b": {
       "attrs": {
        "height": 0.3606837606837607,
        "width": 0.8,
        "x": 0.1,
        "y": 0.3803418803418803
       },
       "content": {
        "cell": "e0937ba9-ac52-4500-9355-f809320da00f",
        "part": "whole"
       },
       "id": "4235e07a-e2e1-494e-aa2e-44cb3bc0908b"
      },
      "adaea460-ec30-45f6-9737-4561f15e31ee": {
       "attrs": {
        "height": 1,
        "width": 1,
        "x": 0,
        "y": 0
       },
       "id": "adaea460-ec30-45f6-9737-4561f15e31ee"
      }
     }
    },
    "9d0acc82-b4d0-4258-bfcb-54751095872c": {
     "id": "9d0acc82-b4d0-4258-bfcb-54751095872c",
     "prev": "019925b6-3427-4056-b7b3-037d5ada7af0",
     "regions": {
      "781dd65e-f4a6-499c-9faa-ad4ff58b0831": {
       "attrs": {
        "height": 0.14017094017094017,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "fcdb542e-a920-41f2-9b8b-a6fe3b47f4a4",
        "part": "whole"
       },
       "id": "781dd65e-f4a6-499c-9faa-ad4ff58b0831"
      },
      "b3c79e42-7512-4bfd-b2ae-c80a3e377d75": {
       "attrs": {
        "height": 0.6017094017094017,
        "width": 0.8076923076923077,
        "x": 0.1,
        "y": 0.2982905982905983
       },
       "content": {
        "cell": "ae7b3af1-e0c2-4011-8fb6-ae6794c5dfa9",
        "part": "whole"
       },
       "id": "b3c79e42-7512-4bfd-b2ae-c80a3e377d75"
      },
      "ceb2aead-3ab9-410a-b5f0-1e66ef2f5d9d": {
       "attrs": {
        "height": 0.2,
        "width": 0.4,
        "x": 0.5,
        "y": 0.7
       },
       "id": "ceb2aead-3ab9-410a-b5f0-1e66ef2f5d9d"
      }
     }
    },
    "9fd2fc08-8f31-40b1-9c43-bc006b638a09": {
     "id": "9fd2fc08-8f31-40b1-9c43-bc006b638a09",
     "prev": "eb430d24-2743-4147-b4d8-4dfe9fe354f9",
     "regions": {
      "53c2d421-95f8-4bf5-91ce-2bf61fcf4145": {
       "attrs": {
        "height": 1,
        "width": 1,
        "x": 0,
        "y": 0
       },
       "content": {
        "cell": "213eb2b0-b658-46ce-a72f-215a82c5cc7c",
        "part": "whole"
       },
       "id": "53c2d421-95f8-4bf5-91ce-2bf61fcf4145"
      }
     }
    },
    "c640b2e3-23c3-406e-a06e-88bc91506535": {
     "id": "c640b2e3-23c3-406e-a06e-88bc91506535",
     "prev": "3a0e5011-0f74-4bc4-b4dd-84d1602d1e4d",
     "regions": {
      "79a80fb9-9819-4190-b9a3-b0fe1afa1e25": {
       "attrs": {
        "height": 0.8,
        "width": 0.45,
        "x": 0.5,
        "y": 0.1
       },
       "content": {
        "cell": "15f3fbd2-0e7f-4ceb-93c1-8936cdebed7b",
        "part": "whole"
       },
       "id": "79a80fb9-9819-4190-b9a3-b0fe1afa1e25"
      },
      "e05cb8bc-bd5a-4d46-ae12-98c99fdd9779": {
       "attrs": {
        "height": 0.8,
        "width": 0.45,
        "x": 0.05,
        "y": 0.1
       },
       "content": {
        "cell": "5e1738d7-c5be-46f1-a9b0-9d6644551c9e",
        "part": "whole"
       },
       "id": "e05cb8bc-bd5a-4d46-ae12-98c99fdd9779"
      }
     }
    },
    "ca856989-0a9b-4281-83e3-ded0c06af816": {
     "id": "ca856989-0a9b-4281-83e3-ded0c06af816",
     "prev": null,
     "regions": {
      "1975c898-ce9f-41ab-a66e-8308c8b18983": {
       "attrs": {
        "height": 1,
        "width": 1,
        "x": 0,
        "y": 0
       },
       "content": {
        "cell": "eff3a02c-cf13-4c08-b2b3-df48c676159c",
        "part": "whole"
       },
       "id": "1975c898-ce9f-41ab-a66e-8308c8b18983"
      }
     }
    },
    "eb430d24-2743-4147-b4d8-4dfe9fe354f9": {
     "id": "eb430d24-2743-4147-b4d8-4dfe9fe354f9",
     "prev": "7d81e3c9-81e7-4c29-8022-538a15107a84",
     "regions": {
      "5597e743-7b5e-48e7-beb5-0a93c51dd3ed": {
       "attrs": {
        "height": 1,
        "width": 1,
        "x": 0,
        "y": 0
       },
       "content": {
        "cell": "30af4bd1-d2ec-47ec-bd16-aefe3514f0f1",
        "part": "whole"
       },
       "id": "5597e743-7b5e-48e7-beb5-0a93c51dd3ed"
      }
     }
    }
   },
   "themes": {}
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
